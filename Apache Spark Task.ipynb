{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi everyone! Glad you are here!\n",
    "\n",
    "This is one of the test tasks that I was asked to complete as a part of the interview process. I had to:\n",
    "1. Transform the file from xlsx to parquet;\n",
    "2. Conduct data quality checks;\n",
    "3. Rename columns and aggrefate the data;\n",
    "4. Convert one currency to another;\n",
    "5. Save the file back to csv and load in to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33a5523f-6bb4-425f-a622-83b327d64e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8cd2cc-cb89-425b-bd96-56da9745ce32",
   "metadata": {},
   "source": [
    "### 1. Transformation\n",
    "There were some difficulties with the library installation, so I just decided to use pandas to turn xlsx to csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "f436cb1a-b55a-4d09-a1ad-72bcaa80974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = pd.read_excel('/Users/Savelyev_Ilya/Downloads/Тестовое/Source/DetailSales.xlsx')\n",
    "prep['Fecha'] = pd.to_datetime(prep['Fecha'])\n",
    "prep['Creado'] = pd.to_datetime(prep['Creado'])\n",
    "prep.to_csv('/Users/Savelyev_Ilya/Downloads/Тестовое/Source/DetailSales.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "25851616-6961-43d4-be74-5586999924ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").option('header', True).option('inferSchema', True).load('/Users/Savelyev_Ilya/Downloads/Тестовое/Source/DetailSales.csv')\n",
    "df.write.mode('overwrite').parquet('/Users/Savelyev_Ilya/Downloads/Тестовое/Stage/DetailSales.pqt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1257843f-cee9-4d55-b390-529ce3ee782b",
   "metadata": {},
   "source": [
    "### 2. Moving the source\n",
    "Just use the bash command here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "8aea9119-0c71-468c-b512-f1ce185d953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /Users/Savelyev_Ilya/Downloads/Тестовое/Source/DetailSales.xlsx /Users/Savelyev_Ilya/Downloads/Тестовое/Archive/DetailSales.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9283acae-bf3f-4749-9fc8-3b8a38f75fb9",
   "metadata": {},
   "source": [
    "### 3. Working with parquet\n",
    "To begin, let's just take a look at the dataset and at the columns' datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "03de5bb3-fd44-418b-8f7f-7c4b6532a30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+---------------+--------+------+-----+--------+----------+-------+-------------------+--------+\n",
      "|      id|Orden ID|Producto|         Nombre|Cantidad|Precio|Total|Vendedor|     Fecha|Usuario|             Creado|Impuesto|\n",
      "+--------+--------+--------+---------------+--------+------+-----+--------+----------+-------+-------------------+--------+\n",
      "|3b1c962d|e72de456|      50|COLOR RAIZ X50G|       3|   700| 2100|9f04044e|2021-01-08|  ADMIN|2021-12-06 06:41:00|    1.19|\n",
      "|037b90c1|52ad5614|      50|COLOR RAIZ X50G|       4|   700| 2800|9f04044e|2021-01-10|  ADMIN|2021-12-06 08:11:00|    1.19|\n",
      "|7addf8af|d1c1e8db|      50|COLOR RAIZ X50G|       6|   700| 4200|9f04044e|2021-02-08|  ADMIN|2021-12-06 08:56:00|    1.19|\n",
      "|7c6dc67f|c7b6cf8c|      50|COLOR RAIZ X50G|      12|   700| 8400|9f04044e|2021-02-08|  ADMIN|2021-12-06 08:59:00|    1.19|\n",
      "|69b6d156|1a248fee|      50|COLOR RAIZ X50G|       6|   700| 4200|c5abb107|2021-02-10|  ADMIN|2021-12-06 09:35:00|    1.19|\n",
      "+--------+--------+--------+---------------+--------+------+-----+--------+----------+-------+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- Orden ID: string (nullable = true)\n",
      " |-- Producto: integer (nullable = true)\n",
      " |-- Nombre: string (nullable = true)\n",
      " |-- Cantidad: integer (nullable = true)\n",
      " |-- Precio: integer (nullable = true)\n",
      " |-- Total: integer (nullable = true)\n",
      " |-- Vendedor: string (nullable = true)\n",
      " |-- Fecha: date (nullable = true)\n",
      " |-- Usuario: string (nullable = true)\n",
      " |-- Creado: timestamp (nullable = true)\n",
      " |-- Impuesto: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"parquet\").load('/Users/Savelyev_Ilya/Downloads/Тестовое/Stage/DetailSales.pqt')\n",
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f237f98-8126-4d21-8159-bb3073a02da1",
   "metadata": {},
   "source": [
    "As we can see, all the columns have the correct datatypes.\n",
    "\n",
    "Now, let's list the major data quality checks we would like to conduct:\n",
    "\n",
    "1. Uniqueness of rows\n",
    "2. Abscence of null-values\n",
    "3. Reasonable date range\n",
    "4. Abscence of the non-positive values in the numeric columns (Cantidad, Precio, Total)\n",
    "5. While the following equation is reasonable - Total = Precio * Cantidad, I would like to check that this rule is met in all of the records\n",
    " \n",
    "\n",
    "#### 1. Uniqueness of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "a027438d-df99-419d-91bf-2fc472adaac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25158"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6120ddb2-13b8-4b70-9fb8-858f5823cf96",
   "metadata": {},
   "source": [
    "The quantity of rows and unique indetifiers is the same - 25158 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "b69f20c4-98b0-483f-b34b-4f9c372d7fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(count(DISTINCT id)=25158)]"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.agg(F.countDistinct(df.id)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed89699-18e2-4351-ba03-82e4fd89004a",
   "metadata": {},
   "source": [
    "#### 2. Abscence of null-values\n",
    "We need to make sure, that there are no cells with null-values, otherwise we have to decide, what to do with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "cc36a614-9b32-4a31-9b3f-a298e84a2d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'Orden ID': 0,\n",
       " 'Producto': 0,\n",
       " 'Nombre': 0,\n",
       " 'Cantidad': 0,\n",
       " 'Precio': 0,\n",
       " 'Total': 0,\n",
       " 'Vendedor': 0,\n",
       " 'Fecha': 0,\n",
       " 'Usuario': 0,\n",
       " 'Creado': 0,\n",
       " 'Impuesto': 0}"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls = {}\n",
    "\n",
    "for column in df.columns:\n",
    "    nulls[column] = df.filter(F.col(f'{column}').isNull()).count()\n",
    "\n",
    "nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64de0abe-458f-4ac0-977c-b5c67bd2f5c5",
   "metadata": {},
   "source": [
    "No null-values found, we can move on.\n",
    "\n",
    "#### 3. Reasonable date range\n",
    "Let's make sure that there aren't any abnormal dates in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "e694485d-cdc5-4cca-a86d-93c5a2e2d958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(min(Fecha)=datetime.date(2021, 1, 8))]"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.agg(F.min(df.Fecha)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "9291198d-8c9c-48d9-a844-34b916bfa46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max(Fecha)=datetime.date(2023, 3, 15))]"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.agg(F.max(df.Fecha)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "fd2cd450-f947-4446-b982-5db8859c3d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(min(Creado)=datetime.datetime(2021, 4, 8, 0, 0))]"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.agg(F.min(df.Creado)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "34b8d093-015e-49f9-bf76-a6a622ce4e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max(Creado)=datetime.datetime(2023, 3, 15, 14, 40, 5))]"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.agg(F.max(df.Creado)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90be5be-db32-46d5-b881-eb6f5e9635e3",
   "metadata": {},
   "source": [
    "There were no abnormal dates found. I am a bit confused that Fecha and Creado somewhere have the same value and somewhere there is a disctance in almost a year. In reality, it could be anomaly, so I would analyze how these two columns are correlated to each other and clean or replace records if needed. While now I don't have this information, I will assume that everything is okay and will move forward to the next check.\n",
    "\n",
    "#### 4. Abscense of non-positive values in the numeric columns\n",
    "It's reasonable to assume, that it is impossible to order a negative or zero amount of a product or buy it for the negavive or zero amount of money. Thus, I have to check that there are no non-positive values in Cantidad, Precio and Total columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "208b8bea-5c18-46c2-8bad-e52e39f44449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------+------+--------+------+-----+--------+-----+-------+------+--------+\n",
      "| id|Orden ID|Producto|Nombre|Cantidad|Precio|Total|Vendedor|Fecha|Usuario|Creado|Impuesto|\n",
      "+---+--------+--------+------+--------+------+-----+--------+-----+-------+------+--------+\n",
      "+---+--------+--------+------+--------+------+-----+--------+-----+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter('Precio <= 0 or Cantidad <= 0 or Total <= 0').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebdada4-3d22-411b-8df1-00fdad28e4c4",
   "metadata": {},
   "source": [
    "Business logic is not violated, we can move forward.\n",
    "\n",
    "#### 5. Validity of the equation Total = Precio * Cantidad\n",
    "While the total amount of money spent equals the product of the price and quantity, let's make sure that all the records meet this rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "0142ca23-bf96-40fa-89c2-1f7240b806cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------+------+--------+------+-----+--------+-----+-------+------+--------+\n",
      "| id|Orden ID|Producto|Nombre|Cantidad|Precio|Total|Vendedor|Fecha|Usuario|Creado|Impuesto|\n",
      "+---+--------+--------+------+--------+------+-----+--------+-----+-------+------+--------+\n",
      "+---+--------+--------+------+--------+------+-----+--------+-----+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter('Precio * Cantidad != Total').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd5005-d70a-4462-938e-edebb9404a55",
   "metadata": {},
   "source": [
    "There are no such records. Great!\n",
    "\n",
    "All the major data quality checks are conducted. We can go to the next step of our task.\n",
    "\n",
    "Next, we have to rename some of the columns and leave only them in the dataframe.\n",
    "\n",
    "Here, in the course of the task, I found that it is required to aggregate by number of pieces and price, but the question arises how to aggregate by price. If the price of the product is the same in the context of the day, there are no problems, and if it changes, then there is a problem. If we take the average price value for the day, the data may also be incorrect, because it will not take into account how many pieces were bought at each price. The most accurate result will be dividing the amount of revenue per day by the number of units sold, then we will get a weighted average price per day. In this regard, I will allow myself a small deviation from the instructions during the execution of the task. The final dataset will be in the format that is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "8dbbc561-6367-49b7-b7f9-6ea62fccc93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------+------------------+\n",
      "|      date|Product_ID|        Product_Name|Quantity|            Amount|\n",
      "+----------+----------+--------------------+--------+------------------+\n",
      "|2022-10-17|        50|AZAFRAN DE RAIZ X50G|      14|             900.0|\n",
      "|2022-11-28|        50|AZAFRAN DE RAIZ X50G|      18|             900.0|\n",
      "|2022-12-03|        53| CANELA ASTILLA X20G|      30|            3200.0|\n",
      "|2022-05-10|        54|     SAL DE AJO X20G|       3|             600.0|\n",
      "|2022-01-26|        57|        CURCUMA X40G|       4|            1500.0|\n",
      "|2022-03-10|        58|    COLOR SUPER X30G|      16|             500.0|\n",
      "|2022-04-19|        58|    COLOR SUPER X30G|       8|             500.0|\n",
      "|2021-05-08|        61|     UVAS PASAS X40G|      13|             920.0|\n",
      "|2021-11-18|        67| CANELA ASTILLA X10G|      30|            1400.0|\n",
      "|2021-01-08|        68|  CANELA MOLIDA X10G|       6|            1200.0|\n",
      "|2022-08-02|        68|  CANELA MOLIDA X10G|       9|             800.0|\n",
      "|2022-04-02|        70|    CLAVO ENTERO X5G|       4|             800.0|\n",
      "|2021-12-28|        70|    CLAVO ENTERO X5G|      58|             800.0|\n",
      "|2022-08-24|        71|ANIS ESTRELLADO X10G|       5|            1600.0|\n",
      "|2022-03-29|        71|ANIS ESTRELLADO X10G|       9|1333.3333333333333|\n",
      "|2022-05-25|        79|    BICARBONATO X50G|      24|             600.0|\n",
      "|2022-02-05|        83|          CURRY X20G|       6|             950.0|\n",
      "|2021-11-12|        86|PIMIENTA ENTERA X10G|       5|             750.0|\n",
      "|2023-01-07|        86|PIMIENTA ENTERA X10G|       2|             800.0|\n",
      "|2022-08-16|        88|PIMIENTA MOLIDA X10G|      16|             850.0|\n",
      "+----------+----------+--------------------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agg = df.select(\n",
    "    F.col('Producto').alias('Product_ID'), \n",
    "    F.col('Nombre').alias('Product_Name'), \n",
    "    F.col('Cantidad').alias('Quantity'), \n",
    "    F.col('Total'),\n",
    "    F.col('Fecha').alias('date')\n",
    ").groupby(\n",
    "    'date',\n",
    "    'Product_ID',\n",
    "    'Product_Name'\n",
    ").agg(\n",
    "    {\n",
    "        'Quantity': 'sum',\n",
    "        'Total': 'sum'\n",
    "    }\n",
    ").withColumn(\n",
    "    'Amount',\n",
    "    F.col('sum(Total)') / F.col('sum(Quantity)')\n",
    ").select(\n",
    "    'date',\n",
    "    'Product_ID',\n",
    "    'Product_Name',\n",
    "    F.col('sum(Quantity)').alias('Quantity'),\n",
    "    'Amount',\n",
    ")\n",
    "\n",
    "agg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1ee1ba-f276-41fd-8205-4271e5269883",
   "metadata": {},
   "source": [
    "In the original excel file, the numbers in the Precio column (now Amount) were in USD. The task requires you to convert prices to rubles on the appropriate date. To get the current exchange rates, I will use the free open API from the site https://currencybeacon.com . I will take 3 years of data from 2021 to 2023 with a reserve, make a dataframe of them and then combine them with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "4639c4f9-3c38-4347-8d23-68b69906bd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- USDRUB: double (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n",
      "+-----------+----------+\n",
      "|     USDRUB|      date|\n",
      "+-----------+----------+\n",
      "|74.00082406|2021-01-01|\n",
      "|74.02350872|2021-01-02|\n",
      "|73.82344403|2021-01-03|\n",
      "|74.27699404|2021-01-04|\n",
      "|74.00834907|2021-01-05|\n",
      "+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests as r\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "token = os.getenv(\"CURRENCY_TOKEN\")\n",
    "rows = []\n",
    "current_date = datetime(2021, 1, 1)\n",
    "\n",
    "while current_date < datetime(2024, 1, 1):\n",
    "\n",
    "    date_iso = current_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    url = f'https://api.currencybeacon.com/v1/historical?api_key={token}&base=USD&date={date_iso}&symbols=RUB'\n",
    "\n",
    "    response = r.get(url)\n",
    "    res = json.loads(response.text)\n",
    "\n",
    "    row = {'date': res['response']['date'], 'USDRUB': res['response']['rates']['RUB']}\n",
    "    rows.append(row)\n",
    "\n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "usdrub = spark.createDataFrame(rows)\n",
    "usdrub = usdrub.withColumn('date', F.to_date('date'))\n",
    "usdrub.printSchema()\n",
    "usdrub.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "780bcbbb-b677-4b1d-b3e4-3b4b1fe0edfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------+------+------------+\n",
      "|      date|Product_ID|        Product_Name|Quantity|Amount|      USDRUB|\n",
      "+----------+----------+--------------------+--------+------+------------+\n",
      "|2022-11-28|        50|AZAFRAN DE RAIZ X50G|      18| 900.0| 61.11183603|\n",
      "|2022-12-03|        53| CANELA ASTILLA X20G|      30|3200.0| 62.57337995|\n",
      "|2022-05-10|        54|     SAL DE AJO X20G|       3| 600.0| 69.77218835|\n",
      "|2022-10-17|        50|AZAFRAN DE RAIZ X50G|      14| 900.0| 62.07689851|\n",
      "|2022-03-10|        58|    COLOR SUPER X30G|      16| 500.0|132.68608142|\n",
      "+----------+----------+--------------------+--------+------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agg = agg.join(usdrub, how='left_outer', on='date')\n",
    "agg.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ada87e-03f6-4bc2-a5f6-b245ba3638bf",
   "metadata": {},
   "source": [
    "We make the final transformations and get the final dataframe. I rounded the prices in rubles to two characters only for better readability within the framework of the test task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "7ddac369-0b67-4e96-9393-0708ec92ca60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+--------+---------+\n",
      "|      date|Product_ID|        Product_Name|Quantity|   Amount|\n",
      "+----------+----------+--------------------+--------+---------+\n",
      "|17.10.2022|        50|AZAFRAN DE RAIZ X50G|      14| 55869.21|\n",
      "|28.11.2022|        50|AZAFRAN DE RAIZ X50G|      18| 55000.65|\n",
      "|03.12.2022|        53| CANELA ASTILLA X20G|      30|200234.82|\n",
      "|10.05.2022|        54|     SAL DE AJO X20G|       3| 41863.31|\n",
      "|26.01.2022|        57|        CURCUMA X40G|       4| 119283.6|\n",
      "|10.03.2022|        58|    COLOR SUPER X30G|      16| 66343.04|\n",
      "|19.04.2022|        58|    COLOR SUPER X30G|       8| 40547.97|\n",
      "|08.05.2021|        61|     UVAS PASAS X40G|      13|  67846.1|\n",
      "|18.11.2021|        67| CANELA ASTILLA X10G|      30|102163.51|\n",
      "|08.01.2021|        68|  CANELA MOLIDA X10G|       6| 88904.82|\n",
      "|02.08.2022|        68|  CANELA MOLIDA X10G|       9|  48498.5|\n",
      "|02.04.2022|        70|    CLAVO ENTERO X5G|       4| 68599.32|\n",
      "|28.12.2021|        70|    CLAVO ENTERO X5G|      58| 59038.54|\n",
      "|24.08.2022|        71|ANIS ESTRELLADO X10G|       5| 95706.25|\n",
      "|29.03.2022|        71|ANIS ESTRELLADO X10G|       9|119241.75|\n",
      "|25.05.2022|        79|    BICARBONATO X50G|      24| 35713.06|\n",
      "|05.02.2022|        83|          CURRY X20G|       6| 71676.97|\n",
      "|12.11.2021|        86|PIMIENTA ENTERA X10G|       5| 54653.77|\n",
      "|07.01.2023|        86|PIMIENTA ENTERA X10G|       2|  58000.2|\n",
      "|16.08.2022|        88|PIMIENTA MOLIDA X10G|      16| 51804.94|\n",
      "+----------+----------+--------------------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df = agg.withColumn(\n",
    "    'Amount', F.round(F.col('Amount') * F.col('USDRUB'), 2)\n",
    ").select(\n",
    "    F.date_format(F.col('date'), 'dd.MM.yyyy').alias('date'),\n",
    "    'Product_ID',\n",
    "    'Product_Name',\n",
    "    'Quantity',\n",
    "    'Amount'\n",
    ")\n",
    "\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca11c2-4f3e-425b-a462-74314b5d381b",
   "metadata": {},
   "source": [
    "Saving the result to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "5e24eadb-0b4a-4713-b32d-5b54ddb2cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.write.mode('overwrite').csv('/Users/Savelyev_Ilya/Downloads/Тестовое/Business/Sales.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972ff55-a7b3-4dce-a37e-5e7d087c307c",
   "metadata": {},
   "source": [
    "Also, in the task, you need to upload data to any DBMS. Due to the fact that I am very limited in time, I will allow myself not to connect Spark to the database using JDBC, but I will transform the dataframe into Pandas and upload it using the PostgreSQL connection I already have, raised in Docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "e3ce3811-dc15-4696-83a3-070be5c4589c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "df_pd = final_df.toPandas()\n",
    "engine = create_engine('postgresql+psycopg2://admin:12345@localhost:5432/test_db')\n",
    "df_pd.to_sql(name='sales', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7725e01-f821-4e30-9a27-1e9bd6396af5",
   "metadata": {},
   "source": [
    "Let's make a test query to the table to check that everything is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "87ff2d0a-7664-4657-8bc0-4730fe88b1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Product_Name</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.10.2022</td>\n",
       "      <td>50</td>\n",
       "      <td>AZAFRAN DE RAIZ X50G</td>\n",
       "      <td>14</td>\n",
       "      <td>55869.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.11.2022</td>\n",
       "      <td>50</td>\n",
       "      <td>AZAFRAN DE RAIZ X50G</td>\n",
       "      <td>18</td>\n",
       "      <td>55000.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03.12.2022</td>\n",
       "      <td>53</td>\n",
       "      <td>CANELA ASTILLA X20G</td>\n",
       "      <td>30</td>\n",
       "      <td>200234.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.05.2022</td>\n",
       "      <td>54</td>\n",
       "      <td>SAL DE AJO X20G</td>\n",
       "      <td>3</td>\n",
       "      <td>41863.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.01.2022</td>\n",
       "      <td>57</td>\n",
       "      <td>CURCUMA X40G</td>\n",
       "      <td>4</td>\n",
       "      <td>119283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13067</th>\n",
       "      <td>19.10.2021</td>\n",
       "      <td>177</td>\n",
       "      <td>LINAZA 250G</td>\n",
       "      <td>3</td>\n",
       "      <td>191434.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13068</th>\n",
       "      <td>16.03.2022</td>\n",
       "      <td>188</td>\n",
       "      <td>EMPAQUE DE CHORIZO X4M</td>\n",
       "      <td>3</td>\n",
       "      <td>453542.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13069</th>\n",
       "      <td>27.12.2022</td>\n",
       "      <td>193</td>\n",
       "      <td>CAJITA BICARBONATO X10G</td>\n",
       "      <td>14</td>\n",
       "      <td>28230.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13070</th>\n",
       "      <td>10.10.2022</td>\n",
       "      <td>227</td>\n",
       "      <td>SALSA NEGRA X120ML</td>\n",
       "      <td>6</td>\n",
       "      <td>88737.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13071</th>\n",
       "      <td>10.03.2022</td>\n",
       "      <td>91</td>\n",
       "      <td>POLVO PARA HORNEAR X 20G</td>\n",
       "      <td>3</td>\n",
       "      <td>106148.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13072 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  Product_ID              Product_Name  Quantity     Amount\n",
       "0      17.10.2022          50      AZAFRAN DE RAIZ X50G        14   55869.21\n",
       "1      28.11.2022          50      AZAFRAN DE RAIZ X50G        18   55000.65\n",
       "2      03.12.2022          53       CANELA ASTILLA X20G        30  200234.82\n",
       "3      10.05.2022          54           SAL DE AJO X20G         3   41863.31\n",
       "4      26.01.2022          57              CURCUMA X40G         4  119283.60\n",
       "...           ...         ...                       ...       ...        ...\n",
       "13067  19.10.2021         177               LINAZA 250G         3  191434.42\n",
       "13068  16.03.2022         188    EMPAQUE DE CHORIZO X4M         3  453542.16\n",
       "13069  27.12.2022         193   CAJITA BICARBONATO X10G        14   28230.11\n",
       "13070  10.10.2022         227        SALSA NEGRA X120ML         6   88737.48\n",
       "13071  10.03.2022          91  POLVO PARA HORNEAR X 20G         3  106148.87\n",
       "\n",
       "[13072 rows x 5 columns]"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql('select * from sales', con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ff8b3b-1606-4b2c-b03c-c0e2eef825cd",
   "metadata": {},
   "source": [
    "The data has been successfully uploaded to the database, the last part of the task - visualization of the results in Power BI can be viewed at this link: https://app.powerbi.com/view?r=eyJrIjoiMzE5YzdmODYtNGFkMC00ZGVlLWI2ODUtMDQwYmFiMTIxMTE5IiwidCI6ImI3ZjgxMzlhLWEwYTUtNGU0Ny05MGExLTI1OGNjZjE5MTYxNSIsImMiOjl9\n",
    "\n",
    "Thanks for your attention!</br>\n",
    "Sincerely,</br> \n",
    "Ilya Savelev"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
